{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_in  = \"/home/carl/spark/examples/carl_Spark/data/mllib/twtr15053001.csv\"\n",
    "twts_df01 = pd.read_csv(csv_in, sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            2520\n",
       "created_at    2520\n",
       "user_id       2520\n",
       "user_name     2520\n",
       "tweet_text    2520\n",
       "url           2520\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twts_df01.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: tweet_text, dtype: object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twtstxt_ls02_utf8 = twts_df01['tweet_text']\n",
    "twtstxt_ls02_utf8[7000:7010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.267964s\n",
      "n_samples: 2520, n_features: 1960\n",
      "(2520, 1960)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=20000, min_df=2, stop_words='english', use_idf=True)\n",
    "X = vectorizer.fit_transform(twtstxt_ls02_utf8)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" %  X.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=7, n_init=1,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
      "    verbose=1) \n",
      "Initialization complete\n",
      "Iteration  0, inertia 3913.361\n",
      "Iteration  1, inertia 2258.759\n",
      "Iteration  2, inertia 2225.844\n",
      "Iteration  3, inertia 2103.791\n",
      "Iteration  4, inertia 2051.639\n",
      "Iteration  5, inertia 2012.006\n",
      "Iteration  6, inertia 2007.627\n",
      "Converged at iteration 6\n",
      "done in 0.162s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=7, init='k-means++', max_iter=100, n_init=1, verbose=1)\n",
    "print(\"Clustering sparse data with %s \" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster0:\n",
      "makes\n",
      "emtmac0kgq\n",
      "competition\n",
      "sense\n",
      "maybe\n",
      "chart\n",
      "receiver\n",
      "depth\n",
      "easier\n",
      "async\n",
      "kerwinfranks\n",
      "coroutines\n",
      "rzkbwm6ebf\n",
      "really\n",
      "thanks\n",
      "spark\n",
      "rt\n",
      "python\n",
      "fortune\n",
      "fun\n",
      "()\n",
      "Cluster1:\n",
      "baybryj\n",
      "vply6hu0yo\n",
      "whee\n",
      "released\n",
      "worked\n",
      "6b1\n",
      "thanks\n",
      "gvanrossum\n",
      "rt\n",
      "python\n",
      "forexnews\n",
      "format\n",
      "fortune\n",
      "fp2txhfj85\n",
      "forums\n",
      "ford\n",
      "foot\n",
      "forward\n",
      "founder\n",
      "foxnews\n",
      "()\n",
      "Cluster2:\n",
      "bad\n",
      "life\n",
      "fp2txhfj85\n",
      "bright\n",
      "これを聴き始めたら雨あがった\n",
      "と同時に木村八段登場\n",
      "sing\n",
      "equal\n",
      "w87s32ra7s\n",
      "promises\n",
      "does\n",
      "look\n",
      "youtube\n",
      "day\n",
      "monty\n",
      "python\n",
      "foxnews\n",
      "forward\n",
      "forums\n",
      "fortune\n",
      "()\n",
      "Cluster3:\n",
      "check\n",
      "deserved\n",
      "lj3dkeeoph\n",
      "model\n",
      "ycvgwdxqnq\n",
      "vivgcme5wi\n",
      "visit\n",
      "falbala\n",
      "eventbrite\n",
      "techsquare\n",
      "ydt8py5ldu\n",
      "labs\n",
      "django\n",
      "bootcamp\n",
      "gt\n",
      "iama_programmer\n",
      "amjoxggt5y\n",
      "timestampable\n",
      "mixin\n",
      "simple\n",
      "()\n",
      "Cluster4:\n",
      "python\n",
      "spark\n",
      "rt\n",
      "plug\n",
      "clinton\n",
      "hillary\n",
      "amp\n",
      "rare\n",
      "programming\n",
      "jobs\n",
      "tractor\n",
      "bulb\n",
      "old\n",
      "farm\n",
      "auto\n",
      "hit\n",
      "glass\n",
      "antique\n",
      "piggy\n",
      "miss\n",
      "()\n",
      "Cluster5:\n",
      "php\n",
      "la\n",
      "javascript\n",
      "python\n",
      "technews\n",
      "programmers\n",
      "wonxp3xdwr\n",
      "happyprogrammersday\n",
      "js\n",
      "code\n",
      "java\n",
      "en\n",
      "programming\n",
      "lyft\n",
      "pink\n",
      "paint\n",
      "paid\n",
      "famous\n",
      "stick\n",
      "sf\n",
      "()\n",
      "Cluster6:\n",
      "yahoo\n",
      "aol\n",
      "deal\n",
      "ceo\n",
      "job\n",
      "changes\n",
      "says\n",
      "tim\n",
      "armstrong\n",
      "spark\n",
      "reuters\n",
      "1wnp9mqmkb\n",
      "wmorwkykie\n",
      "verizon\n",
      "yahoofinance\n",
      "ldnub75mux\n",
      "0ss4m2cbbg\n",
      "wmorwk\n",
      "pic\n",
      "y97arojqgz\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(7):\n",
    "    print(\"Cluster%d:\" % i)\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print('%s' % terms[ind])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDS(dissimilarity='euclidean', eps=0.001, max_iter=300, metric=True,\n",
       "  n_components=2, n_init=4, n_jobs=1, random_state=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "MDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   9.87334457e-01   9.92303918e-01 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " [  9.87334457e-01   0.00000000e+00   9.87704035e-01 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " [  9.92303918e-01   9.87704035e-01   0.00000000e+00 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " ..., \n",
      " [  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,  -2.22044605e-16\n",
      "   -2.22044605e-16   7.81682858e-01]\n",
      " [  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,  -2.22044605e-16\n",
      "   -2.22044605e-16   7.81682858e-01]\n",
      " [  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,   7.81682858e-01\n",
      "    7.81682858e-01  -2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(X)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "pos = mds.fit_transform(dist)\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "# print(xs)\n",
    "# print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02236058  0.48471498  0.74806128 ...,  0.26753381  0.14221634\n",
      "  0.15251596]\n",
      "[ 0.66449042  0.45452639 -0.21821199 ..., -0.08043852  0.12945218  0.07012   ]\n"
     ]
    }
   ],
   "source": [
    "print(xs)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520\n",
      "2520\n",
      "      label                                                txt\n",
      "2000      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2001      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2002      4  Single quotes vs. double quotes in Python #pyt...\n",
      "2003      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2004      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2005      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2006      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2007      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2008      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2009      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2010      4  Programming Python by Mark Lutz https://t.co/5...\n",
      "2011      1  Whee!! Python 3.6b1 is now RELEASED: https://t...\n",
      "2012      2  これを聴き始めたら雨あがった、と同時に木村八段登場!! Always Look on the...\n",
      "2013      2  Bad day does not equal bad life. Promises http...\n",
      "2014      5  Again: #HappyProgrammersDay ⌨💻🤓\\r\\n#Programmin...\n",
      "2015      4  The latest \"Music Yiro News\"! https://t.co/bjM...\n",
      "2016      4  Clevertech: Seasoned Python Developer https://...\n",
      "2017      4  The best #Python course for #DataScience is co...\n",
      "2018      4  The best #Python course for #DataScience is co...\n",
      "2019      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2020      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2021      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2022      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2023      4  Single quotes vs. double quotes in Python #pyt...\n",
      "2024      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2025      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2026      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2027      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2028      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2029      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2030      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2031      4  Programming Python by Mark Lutz https://t.co/5...\n",
      "2032      1  Whee!! Python 3.6b1 is now RELEASED: https://t...\n",
      "2033      2  これを聴き始めたら雨あがった、と同時に木村八段登場!! Always Look on the...\n",
      "2034      2  Bad day does not equal bad life. Promises http...\n",
      "2035      5  Again: #HappyProgrammersDay ⌨💻🤓\\r\\n#Programmin...\n",
      "2036      4  The latest \"Music Yiro News\"! https://t.co/bjM...\n",
      "2037      4  Clevertech: Seasoned Python Developer https://...\n",
      "2038      4  The best #Python course for #DataScience is co...\n",
      "2039      4  The best #Python course for #DataScience is co...\n",
      "2040      4  django-simple-forums 1.3.6: A simple forums ap...\n",
      "2041      4  oputils 0.1.13: Open planet python utilities h...\n",
      "2042      4  RT @methane: Python 3.6 の（個人的に）注目の変更点 - methan...\n",
      "2043      5  RT @python_es: Llamada a sedes para la PyConES...\n",
      "2044      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2045      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2046      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2047      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "2048      4  Single quotes vs. double quotes in Python #pyt...\n",
      "2049      1  RT @gvanrossum: Whee!! Python 3.6b1 is now REL...\n",
      "50\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cluster_colors = { 0: '#1b9e77', 1:'#d95f02', 2:'#7570b3', 3:'#e7298a', 4:'#66a61e', 5:'#9990b3', 6:'e8888a' }\n",
    "cluster_names = { 0: 'lady gaga', 1:'python', 2:'iphone', 3:'china', 4:'youtube', 5:'spark', 6:'justinbieber' }\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "print(len(clusters))\n",
    "print(len(twtstxt_ls02_utf8))\n",
    "\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, txt=twtstxt_ls02_utf8))\n",
    "ix_start = 2000\n",
    "ix_stop = 2050\n",
    "df01 = df[ix_start:ix_stop]\n",
    "\n",
    "print(df01[['label', 'txt']])\n",
    "print(len(df01))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "groups = df.groupby('label')\n",
    "groups01 = df01.groupby('label')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17, 10))\n",
    "ax.margins(0.05)\n",
    "\n",
    "\n",
    "for name, group in groups01:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=cluster_names[name], color=cluster_colors[name], mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    ax.tick_params(axis='y', which='both', left='off', top='off', labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)\n",
    "\n",
    "for i in range(ix_start, ix_stop):\n",
    "    ax.text(df01.ix[i]['x'], df01.ix[i]['y'], df01.ix[i]['txt'], size=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
