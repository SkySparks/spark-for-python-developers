{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import twitter\n",
    "import json\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting Streaming Twitter with Streaming Spark via Queue\n",
    "class Tweet(dict):\n",
    "    def __init__(self, tweet_in):\n",
    "        super(Tweet, self).__init__(self)\n",
    "        if tweet_in and 'delete' not in tweet_in:\n",
    "            self['timestamp'] = dateutil.parser.parse(tweet_in[u'created_at']).replace(tzinfo=None).isoformat()\n",
    "            self['text'] = tweet_in['text'].encode('utf-8')\n",
    "            self['hashtags'] = [x['text'].encode('utf-8') for x in tweet_in['entities']['hashtags']]\n",
    "            self['geo'] = tweet_in['geo']['coordinates'] if tweet_in['geo'] else None\n",
    "            self['id'] = tweet_in['id']\n",
    "            self['screen_name'] = tweet_in['user']['screen_name'].encode('utf-8')\n",
    "            self['user_id'] = tweet_in['user']['id']\n",
    "            \n",
    "def connect_twitter():\n",
    "    consumer_key = ''\n",
    "    consumer_secret = ''\n",
    "    access_token = ''\n",
    "    access_secret = ''\n",
    "    twitter_stream = twitter.TwitterStream(auth = twitter.OAuth(\n",
    "            token=access_token, \n",
    "            token_secret=access_secret, \n",
    "            consumer_key=consumer_key, \n",
    "            consumer_secret=consumer_secret))\n",
    "    return twitter_stream\n",
    "\n",
    "def get_next_tweet(twitter_stream):\n",
    "    stream = twitter_stream.statuses.sample(block=True)\n",
    "    tweet_in = None\n",
    "    while not tweet_in or 'delete' in tweet_in:\n",
    "        tweet_in = stream.next()\n",
    "        tweet_parsed = Tweet(tweet_in)\n",
    "    return json.dumps(tweet_parsed)\n",
    "    \n",
    "def process_rdd_queue(twitter_stream):\n",
    "    # Create the queue through witch RDDs can be pushed to a QueueInputDStream\n",
    "    rddQueue = []\n",
    "    for i in range(3):\n",
    "        rddQueue += [ssc.sparkContext.parallelize([get_next_tweet(twitter_stream)], 5)]\n",
    "    \n",
    "    lines = ssc.queueStream(rddQueue)\n",
    "    lines.pprint()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    sc = SparkContext(appName=\"PythonStreamingQueueStream\")\n",
    "    ssc = StreamingContext(sc, 1)\n",
    "    \n",
    "    # Instantiate the twitter_stream\n",
    "    twitter_stream = connect_twitter()\n",
    "    # Get RDD queue of the streams json or parsed\n",
    "    process_rdd_queue(twitter_stream)\n",
    "    \n",
    "    ssc.start()\n",
    "    time.sleep(2)\n",
    "    ssc.stop(stopSparkContext=True, stopGraceFully=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
