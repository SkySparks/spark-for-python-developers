{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import urlparse\n",
    "from pprint import pprint as pp\n",
    "\n",
    "class TwitterAPI(object):\n",
    "    \"\"\"\n",
    "    TwitterAPI class allows the Connection to Twitter via OAuth\n",
    "    once you have registered with Twitter and receive the \n",
    "    necessary credentials\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize and get the twitter credentials\n",
    "    def __init__(self):\n",
    "        consumer_key = '2ttoyoYKzu8XNlh3e3HW2jMNP'\n",
    "        consumer_secret = 'kRjCiF3NNdyCJQFK1liA0gqTMNEBcf1qPFE3KIlsSj3U8gEk0E'\n",
    "        access_token = '2853253536-v8zzqsVgPbGPopZ7K1K78HdDAS3ci0gfQ0ZmUyq'\n",
    "        access_secret = '9RIp81N7Da5zD1V0Zh72VL1TaW16qe51kao8P0WU59Oxk'\n",
    "        \n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = access_token\n",
    "        self.access_secret = access_secret\n",
    "        \n",
    "        # authenticate credentials with Twitter us Oauth \n",
    "        self.auth = twitter.oauth.OAuth(access_token, access_secret, consumer_key, consumer_secret)\n",
    "        # creates registered Twitter API\n",
    "        self.api = twitter.Twitter(auth=self.auth)\n",
    "    \n",
    "    # search Twitter with query q and max result\n",
    "    def searchTwitter(self, q, max_res=10, **kwargs):\n",
    "        search_results = self.api.search.tweets(q=q, count=10, **kwargs)\n",
    "        statuses = search_results['statuses']\n",
    "        max_results  = min(1000, max_res)\n",
    "        \n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                next_results = search_results['search_metadata']['next_results']\n",
    "                \n",
    "            except KeyError as e:\n",
    "                break\n",
    "                \n",
    "            next_results = urlparse.parse_qsl(next_results[1:])\n",
    "            kwargs = dict(next_results)\n",
    "            search_results = self.api.search.tweets(**kwargs)\n",
    "            statuses += search_results['statuses']\n",
    "            \n",
    "            if len(statuses) > max_results:\n",
    "                break\n",
    "                \n",
    "        return statuses\n",
    "                \n",
    "                \n",
    "    # parse tweets as it is collected to extract id, creation date, user id, tweet text\n",
    "    def parseTweets(self, statuses):\n",
    "        return [(status['id'],\n",
    "                 status['created_at'],\n",
    "                 status['user']['id'],\n",
    "                 status['user']['name'],\n",
    "                 status['text'], url['expanded_url'])\n",
    "                    for status in statuses\n",
    "                    for url in status['entities']['urls']\n",
    "        ]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = TwitterAPI()\n",
    "q = \"ApacheSpark\"\n",
    "tsearch = t.searchTwitter(q)\n",
    "tparsed = t.parseTweets(tsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(772302009403711488,\n",
      "  u'Sun Sep 04 05:15:22 +0000 2016',\n",
      "  259226866,\n",
      "  u'Ryan Nel',\n",
      "  u'RT @IBMbigdata: #MachineLearning in #ApacheSpark 2.0: Under the Hood and Over the Rainbow https://t.co/0pi21cPxYl https://t.co/lXPbGB3BjX',\n",
      "  u'http://bit.ly/2ca6lXR'),\n",
      " (772300977940549632,\n",
      "  u'Sun Sep 04 05:11:16 +0000 2016',\n",
      "  136845362,\n",
      "  u'Jai',\n",
      "  u'RT @mapr: #WhiteboardWalkthrough: @ApacheSpark vs. #MapReduce - https://t.co/jbjRhAXtxW https://t.co/dr1eQJtjzy',\n",
      "  u'http://bit.ly/1T2qQnd'),\n",
      " (772298698017509376,\n",
      "  u'Sun Sep 04 05:02:12 +0000 2016',\n",
      "  609187397,\n",
      "  u'Michael Li',\n",
      "  u'RT @IBMbigdata: #MachineLearning in #ApacheSpark 2.0: Under the Hood and Over the Rainbow https://t.co/BxDESgfBEC https://t.co/XOMd6e96Y4',\n",
      "  u'http://bit.ly/2cfHOh6'),\n",
      " (772290631645356032,\n",
      "  u'Sun Sep 04 04:30:09 +0000 2016',\n",
      "  256109210,\n",
      "  u'Ajay Saini',\n",
      "  u'RT @ImDataScientist: #apachespark Is the Future of #Hadoop , Cloudera Says #data #BigData #DataScience https://t.co/OAcPkOUlme https://t.co\\u2026',\n",
      "  u'http://buff.ly/1ODJ8Ij'),\n",
      " (772287649813975042,\n",
      "  u'Sun Sep 04 04:18:18 +0000 2016',\n",
      "  45072729,\n",
      "  u'Pietro F. Menna',\n",
      "  u'RT @openSAP: #SAP #HANA #Vora is an in-memory query engine that plugs into the #ApacheSpark execution framework https://t.co/vFZSjrZUIr',\n",
      "  u'http://spr.ly/6019BNrqR'),\n",
      " (772284157762293760,\n",
      "  u'Sun Sep 04 04:04:26 +0000 2016',\n",
      "  136845362,\n",
      "  u'Jai',\n",
      "  u'RT @databricks: Learn how @Edmunds deployed #ApacheSpark with Databricks to improve data integrity and customer satisfaction: https://t.co/\\u2026',\n",
      "  u'http://dbricks.co/2cxsbq1'),\n",
      " (772280963040698368,\n",
      "  u'Sun Sep 04 03:51:44 +0000 2016',\n",
      "  511740616,\n",
      "  u'BIconnections',\n",
      "  u'RT @ThoHeller: #MachineLearning in #ApacheSpark 2.0: Under the #Hood and over the #Rainnbow:\\nhttps://t.co/iVx0UU0yka\\n#Bigdata @ApacheSpark\\u2026',\n",
      "  u'http://buff.ly/2bTxxrO'),\n",
      " (772279778447597568,\n",
      "  u'Sun Sep 04 03:47:02 +0000 2016',\n",
      "  12660502,\n",
      "  u'frodriguez',\n",
      "  u'RT @ThoHeller: #MachineLearning in #ApacheSpark 2.0: Under the #Hood and over the #Rainnbow:\\nhttps://t.co/iVx0UU0yka\\n#Bigdata @ApacheSpark\\u2026',\n",
      "  u'http://buff.ly/2bTxxrO'),\n",
      " (772279630132752385,\n",
      "  u'Sun Sep 04 03:46:26 +0000 2016',\n",
      "  136845362,\n",
      "  u'Jai',\n",
      "  u'RT @spark_summit: Why should you care about @apachespark object stores? Join @hortonworks to learn why your data depends on it https://t.co\\u2026',\n",
      "  u'http://ssum.it/2bWsZiV'),\n",
      " (772278525470486528,\n",
      "  u'Sun Sep 04 03:42:03 +0000 2016',\n",
      "  1605693206,\n",
      "  u'Marc R Gagn\\xe9 MAPP',\n",
      "  u'RT @ThoHeller: #MachineLearning in #ApacheSpark 2.0: Under the #Hood and over the #Rainnbow:\\nhttps://t.co/iVx0UU0yka\\n#Bigdata @ApacheSpark\\u2026',\n",
      "  u'http://buff.ly/2bTxxrO'),\n",
      " (772278228526501888,\n",
      "  u'Sun Sep 04 03:40:52 +0000 2016',\n",
      "  4695789613,\n",
      "  u'Jim Studio',\n",
      "  u'RT @ThoHeller: #MachineLearning in #ApacheSpark 2.0: Under the #Hood and over the #Rainnbow:\\nhttps://t.co/iVx0UU0yka\\n#Bigdata @ApacheSpark\\u2026',\n",
      "  u'http://buff.ly/2bTxxrO'),\n",
      " (772278019125805056,\n",
      "  u'Sun Sep 04 03:40:02 +0000 2016',\n",
      "  1499201215,\n",
      "  u'Thorsten Heller',\n",
      "  u'#MachineLearning in #ApacheSpark 2.0: Under the #Hood and over the #Rainnbow:\\nhttps://t.co/iVx0UU0yka\\n#Bigdata @ApacheSpark #AI',\n",
      "  u'http://buff.ly/2bTxxrO'),\n",
      " (772248035422146560,\n",
      "  u'Sun Sep 04 01:40:53 +0000 2016',\n",
      "  4838403342,\n",
      "  u'Kirk De Guzman',\n",
      "  u'RT @ImDataScientist: #apachespark Is the Future of #Hadoop , Cloudera Says #data #BigData #DataScience https://t.co/OAcPkOUlme https://t.co\\u2026',\n",
      "  u'http://buff.ly/1ODJ8Ij'),\n",
      " (772247393722957824,\n",
      "  u'Sun Sep 04 01:38:20 +0000 2016',\n",
      "  352174732,\n",
      "  u'Sadagopan',\n",
      "  u'RT @databricks: Learn how @Edmunds deployed #ApacheSpark with Databricks to improve data integrity and customer satisfaction: https://t.co/\\u2026',\n",
      "  u'http://dbricks.co/2cxsbq1'),\n",
      " (772245957522194432,\n",
      "  u'Sun Sep 04 01:32:38 +0000 2016',\n",
      "  2559896360,\n",
      "  u'Turen',\n",
      "  u'RT @ImDataScientist: #apachespark Is the Future of #Hadoop , Cloudera Says #data #BigData #DataScience https://t.co/OAcPkOUlme https://t.co\\u2026',\n",
      "  u'http://buff.ly/1ODJ8Ij'),\n",
      " (772243690358239233,\n",
      "  u'Sun Sep 04 01:23:38 +0000 2016',\n",
      "  511740616,\n",
      "  u'BIconnections',\n",
      "  u'RT @ImDataScientist: #apachespark Is the Future of #Hadoop , Cloudera Says #data #BigData #DataScience https://t.co/OAcPkOUlme https://t.co\\u2026',\n",
      "  u'http://buff.ly/1ODJ8Ij'),\n",
      " (772242791858511872,\n",
      "  u'Sun Sep 04 01:20:03 +0000 2016',\n",
      "  567878250,\n",
      "  u'Tracy Mynehan',\n",
      "  u'RT @databricks: Learn how @Edmunds deployed #ApacheSpark with Databricks to improve data integrity and customer satisfaction: https://t.co/\\u2026',\n",
      "  u'http://dbricks.co/2cxsbq1'),\n",
      " (772242157344137217,\n",
      "  u'Sun Sep 04 01:17:32 +0000 2016',\n",
      "  712106354777956353,\n",
      "  u'S\\xe9amus',\n",
      "  u'RT @IBMbigdata: #MachineLearning in #ApacheSpark 2.0: Under the Hood and Over the Rainbow https://t.co/0pi21cPxYl https://t.co/lXPbGB3BjX',\n",
      "  u'http://bit.ly/2ca6lXR'),\n",
      " (772241590882492416,\n",
      "  u'Sun Sep 04 01:15:17 +0000 2016',\n",
      "  712106354777956353,\n",
      "  u'S\\xe9amus',\n",
      "  u'RT @ImDataScientist: #apachespark Is the Future of #Hadoop , Cloudera Says #data #BigData #DataScience https://t.co/OAcPkOUlme https://t.co\\u2026',\n",
      "  u'http://buff.ly/1ODJ8Ij')]\n"
     ]
    }
   ],
   "source": [
    "pp(tparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
